# Nomo

**A Little Friend for a Big Focus**

Nomo is an interactive desk companion robot built to encourage healthier work habits through computer vision, gesture recognition, and playful nudges. Designed as a capstone project at NYU Abu Dhabi, Nomo blends real-time software with expressive hardware to promote mindful breaks and deep focusâ€”making your workflow a little more human.

---

## ğŸ”§ Features

- ğŸ§  Real-time gesture recognition (wave, closed fist, thumbs-up)
- ğŸ’¡ LED feedback to guide breaks and focus sessions
- ğŸ¤– Raspberry Pi + Arduino integration
- ğŸ¾ Pettable with responsive purring vibration
- ğŸ“ Location-based behavior (work and break zones)
- ğŸ¯ Designed with routines, attention, and well-being in mind

---

## ğŸš€ How It Works

Nomo runs on a Raspberry Pi using Python for vision and logic, paired with an Arduino for motor and sensor control. When placed in a predefined location, it can detect gestures and trigger break/focus states accordingly. Each mode is designed to reflect a balance between productivity and self-care.

> For a full overview of modes, gestures, and setup, see the [Product Manual](link).

---

## ğŸ“ Repository Structure

```bash
nomo/
â”œâ”€â”€ pi/                 # Raspberry Pi scripts (Python - gesture, logic)
â”œâ”€â”€ arduino/            # Arduino sketches (servo, vibration, LEDs)
â”œâ”€â”€ assets/             # Media, logos, mockups
â”œâ”€â”€ docs/               # Product manual, slides, website content
â”œâ”€â”€ web/                # Framer site export or related media
â””â”€â”€ README.md

